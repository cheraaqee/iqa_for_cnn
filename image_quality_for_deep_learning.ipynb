{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c041f7e",
   "metadata": {},
   "source": [
    "# Image Quality for Deep Learning\n",
    "Deep learning feeds on images for performing computer vision tasks. The quality of these input images can be affective in the performance of the networks. Devising a computational model that can predict the performance of CNN on the input image, based on the quality of the image, can be helpful in applying deep learning models.  \n",
    "One approach is to train a second CNN to learn how _good_ an image is. The purpose is to have a CNN that can regress an input image to some value in the ```[0, 1]``` interval. The higher this value, the better the quality of the image to be used by deep learning model. In the following, we describe a scenario for training such a network that we call **metrifier_CNN**.\n",
    "## The End-to-End Approach\n",
    "The input of the **metrifier_CNN** is an image, and its output is the predicted _machine-perceived_ quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67e6ef1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The codes are not optimized nor finalized. They're just an attempt to clarify the proposed idea.\n",
    "# if our metrifier_CNN is a python object, it can have a method called 'evaluate' which predicts\n",
    "# the machine-perceived quality of an image:\n",
    "the_machine_perceived_quality = metrifier_CNN(image_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94c8a6",
   "metadata": {},
   "source": [
    "For training such a network, we need training samples of the form:  \n",
    "```(image, true_machine_perceived_quality)```.  \n",
    "\n",
    "One idea for providing a value for ```true_machine_perceived_quality``` is the performance of some network, in some task, on the image under test. For exampe the accuracy of [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), in image classification task, on one of the [ImageNet](https://arxiv.org/pdf/1409.0575) images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ad29c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_the_loss_of_resnet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhide-output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     ]\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m performance_of_the_worker_CNN \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_the_loss_of_resnet50\u001b[49m(image, image_label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_the_loss_of_resnet50' is not defined"
     ]
    }
   ],
   "source": [
    "performance_of_the_worker_CNN = compute_the_loss_of_resnet50(image, image_label)\n",
    "# Having the image and its label from the ImageNet dataset, 'compute_the_loss_of_resnet50' returns a single value\n",
    "# in the [0, 1] interval as the loss of\n",
    "# tensorflow.keras.applications.resnet50(weights = 'imagenet')\n",
    "# on 'image'. Something like:\n",
    "# import tensorflow as tf\n",
    "# resnet_model = tf.keras.applications.resnet50(incude_top = True, weights = 'imagenet')\n",
    "# resnet_model.trainable = False\n",
    "# resnet_model.compile(optimizer = 'adam',\n",
    "#        loss = tf.keras.losses.SparseCategoricalCrossEntropy(from_logits = True),\n",
    "#        metrics = ['accuracy'])\n",
    "# result = resnet_model.evaluate(image, image_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb0a2b",
   "metadata": {},
   "source": [
    "The ```performance_of_the_worker_CNN``` can be used as the ```true_machine_perceived_quality```. Having the labels for all images in [ImageNet](https://arxiv.org/pdf/1409.0575) and a pre-trained model like [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), as our **worker_CNN**, we can create a dataset of ordered pairs:  \n",
    "```(image_from_a_dataset_for_some_task, performance_of_a_worker_CNN_on_this_image)```.  \n",
    "### An Augmented Task-Specific Dataset\n",
    "The quality of images in [ImageNet](https://arxiv.org/pdf/1409.0575) can be altered from various aspects with synthesized distortions. It is obvious that the task-specific label of an image, which quality has been altered, will remain the same. For example if ```img_1``` is a sample from [ImageNet](https://arxiv.org/pdf/1409.0575) and its label is ```'cat'```, we can add Gaussian noise to it:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e327b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "noisy_image = cv2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
