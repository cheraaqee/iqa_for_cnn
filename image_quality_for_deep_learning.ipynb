{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c041f7e",
   "metadata": {},
   "source": [
    "# Image Quality for Deep Learning\n",
    "Deep learning feeds on images for performing computer vision tasks. The quality of these input images can be affective in the performance of the networks. Devising a computational model that can predict the performance of CNN on the input image, based on the quality of the image, can be helpful in applying deep learning models.  \n",
    "One approach is to train a second CNN to learn how _good_ an image is. The purpose is to have a CNN that can regress an input image to some value in the ```[0, 1]``` interval. The higher this value, the better the quality of the image to be used by deep learning model. In the following, we describe a scenario for training such a network that we call **metrifier_CNN**.\n",
    "## The End-to-End Approach\n",
    "The input of the **metrifier_CNN** is an image, and its output is the predicted _machine-perceived_ quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67e6ef1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !! The codes are not optimized nor finalized. They're just an attempt to clarify the proposed idea.\n",
    "# if our metrifier_CNN is a python object, it can have a method called 'evaluate' which predicts\n",
    "# the machine-perceived quality of an image:\n",
    "the_machine_perceived_quality = metrifier_CNN(image_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94c8a6",
   "metadata": {},
   "source": [
    "For training such a network, we need training samples of the form:  \n",
    "```(image, true_machine_perceived_quality)```.  \n",
    "\n",
    "One idea for providing a value for ```true_machine_perceived_quality``` is the performance of some network, in some task, on the image under test. For exampe the accuracy of [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), in image classification task, on one of the [ImageNet](https://arxiv.org/pdf/1409.0575) images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ad29c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_the_loss_of_resnet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhide-output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     ]\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m performance_of_the_worker_CNN \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_the_loss_of_resnet50\u001b[49m(image, image_label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_the_loss_of_resnet50' is not defined"
     ]
    }
   ],
   "source": [
    "performance_of_the_worker_CNN = compute_the_loss_of_resnet50(image, image_label)\n",
    "# Having the image and its label from the ImageNet dataset, 'compute_the_loss_of_resnet50' returns a single value\n",
    "# in the [0, 1] interval as the loss of\n",
    "# tensorflow.keras.applications.resnet50(weights = 'imagenet')\n",
    "# on 'image'. Something like:\n",
    "# import tensorflow as tf\n",
    "# resnet_model = tf.keras.applications.resnet50(incude_top = True, weights = 'imagenet')\n",
    "# resnet_model.trainable = False\n",
    "# resnet_model.compile(optimizer = 'adam',\n",
    "#        loss = tf.keras.losses.SparseCategoricalCrossEntropy(from_logits = True),\n",
    "#        metrics = ['accuracy'])\n",
    "# result = resnet_model.evaluate(image, image_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb0a2b",
   "metadata": {},
   "source": [
    "The ```performance_of_the_worker_CNN``` can be used as the ```true_machine_perceived_quality```. Having the labels for all images in [ImageNet](https://arxiv.org/pdf/1409.0575) and a pre-trained model like [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), as our **worker_CNN**, we can create a dataset of ordered pairs:  \n",
    "```(image_from_a_dataset_for_some_task, performance_of_a_worker_CNN_on_this_image)```.  \n",
    "### An Augmented Task-Specific Dataset\n",
    "The quality of images in [ImageNet](https://arxiv.org/pdf/1409.0575) can be altered from various aspects with synthesized distortions. It is obvious that the task-specific label of an image, which quality has been altered, will remain the same. For example if ```img_1``` is a sample from [ImageNet](https://arxiv.org/pdf/1409.0575) and its label is ```'cat'```, we can add Gaussian noise to it:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e327b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "im = np.zeros(img_1.shape, np.uint8) \n",
    "mean = 0\n",
    "sigma = 10\n",
    "cv2.randn(im,mean,sigma) \n",
    "img_1_noisy = cv2.add(img, im) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141527d",
   "metadata": {},
   "source": [
    "and ```img_1_noisy``` still represents a cat, but [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) (, the **worker_CNN**,) may have a different performance on ```img_1``` and ```img_1_noisy```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b481b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_prstine = compute_the_loss_of_resnet50(img_1, img_1_label)\n",
    "performance_distorted = compute_the_loss_of_resnet50(img_1_noisy, img_1_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cef6cf",
   "metadata": {},
   "source": [
    "So the label of ```img_1_noisy``` for our **metrifier_CNN** will be equal to ```performance_distorted```. We these explanations we can build our augmented [ImageNet](https://arxiv.org/pdf/1409.0575) (\"**ImageNet_Quality**\") as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf88a965",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ImageNet is considered as a set of samples: (image, label)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[43mImageNet\u001b[49m:\n\u001b[1;32m      3\u001b[0m     (image, label_classification) \u001b[38;5;241m=\u001b[39m get_the_image_and_label(sample)\n\u001b[1;32m      4\u001b[0m     label_quantification \u001b[38;5;241m=\u001b[39m compute_the_loss_of_resnet50(image, label_classification)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageNet' is not defined"
     ]
    }
   ],
   "source": [
    "# ImageNet is considered as a set of samples: (image, label)\n",
    "for sample in ImageNet:\n",
    "    (image, label_classification) = get_the_image_and_label(sample)\n",
    "    for distortion in distortion_types: # for example Gaussian blur, Gaussian noise, Compression loss, ...\n",
    "        for severity in distortion.severity_levels: # each distortion can be applied with various levels of severity\n",
    "            image_distorted = apply_distortion(image, distortion, severity)\n",
    "            label_quantification = compute_the_loss_of_resnet50(image_distorted, label_classification)\n",
    "            add_to_dataset(image_distorted, label_quantification)\n",
    "# 'add_to_dataset' will create a set of samples: (image, label), where image is any distorted version of ImageNet\n",
    "# images and label is a number in [0, 1] which represents the performance of ResNet50 on that image. This set is\n",
    "# the 'ImageNet_Quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903df869",
   "metadata": {},
   "source": [
    "With **ImageNet_Quality**, we can train a CNN that learns to predict the performance of [ResNet50](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) on (hopefully any) image(s). To make the **metrifier_CNN** more agnostic to the **worker_CNN**, we may develop similar functions llike ```compute_the_loss_resnet50``` for a few other classifiers and change the **ImageNet_Quality** accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04434315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for sample in ImageNet:\n",
    "    (image, label_classification) = get_the_image_and_label(sample)\n",
    "    for distortion in distortion_types: \n",
    "        for severity in distortion.severity_levels: \n",
    "            image_distorted = apply_distortion(image, distortion, severity)\n",
    "            # compute the loss of a few image classifier and average them\n",
    "            loss_resnet   = compute_the_loss_of_resnet50        (image_distorted, label_classification)\n",
    "            loss_vgg      = compute_the_loss_of_vgg16           (image_distorted, label_classification)\n",
    "            loss_mobilenet= compute_the_loss_of_mobilenetv2     (image_distorted, label_classification)\n",
    "            loss_inception= compute_the_loss_of_inception       (image_distorted, label_classification)\n",
    "            loss_alexnet  = compute_the_loss_of_alexnet         (image_distorted, label_classification)\n",
    "            label_quantification = np.mean([loss_resnet, loss_vgg, loss_mobilenet, loss_inception, loss_alexnet])\n",
    "            add_to_dataset(image_distorted, label_quantification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31f566",
   "metadata": {},
   "source": [
    "### A Candidate Architecture for ```metrifier_CNN```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
