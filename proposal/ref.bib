@article{fry2018bridging,
	title={Bridging the gap between imaging performance and image quality measures},
	author={Fry, Edward WS and Triantaphillidou, Sophie and Jacobson, Ralph E and Jarvis, John R and Jenkin, Robin B},
	journal={Electronic Imaging},
	volume={2018},
	number={12},
	pages={231--1},
	year={2018},
	publisher={Society for Imaging Science and Technology}
}

@inproceedings{kang2014convolutional,
	title={Convolutional neural networks for no-reference image quality assessment},
	author={Kang, Le and Ye, Peng and Li, Yi and Doermann, David},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1733--1740},
	year={2014}
}


@article{zhai2020perceptual,
	title={Perceptual image quality assessment: a survey},
	author={Zhai, Guangtao and Min, Xiongkuo},
	journal={Science China Information Sciences},
	volume={63},
	number={11},
	pages={1--52},
	year={2020},
	publisher={Springer}
}

@article{stevens1946theory,
	title={On the theory of scales of measurement},
	author={Stevens, Stanley Smith},
	journal={Science},
	volume={103},
	number={2684},
	pages={677--680},
	year={1946},
	publisher={American Association for the Advancement of Science}
}

@book{allen2012manual,
	title={The manual of photography},
	author={Allen, Elizabeth and Triantaphillidou, Sophie},
	year={2012},
	publisher={CRC Press}
}

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year={2016},
	publisher={MIT press}
}

@misc{cisco,
	title        = "Cisco Annual Internet Report",
	author       = "{CISCO}",
	howpublished = "\url{https://www.cisco.com/c/en/us/solutions/executive-perspectives/annual-internet-report/index.html}",
	year         = 2022,
	note         = "Accessed: 2022-July-15"
}
@article{doi:10.1142/S0218001400000519,
	author = {FENG, L. and SUEN, C. Y. and TANG, Y. Y. and YANG, L. H.},
	title = {EDGE EXTRACTION OF IMAGES BY RECONSTRUCTION USING WAVELET DECOMPOSITION DETAILS AT DIFFERENT RESOLUTION LEVELS},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	volume = {14},
	number = {06},
	pages = {779-793},
	year = {2000},
	doi = {10.1142/S0218001400000519},

	URL = { 
https://doi.org/10.1142/S0218001400000519

	},
	eprint = { 
https://doi.org/10.1142/S0218001400000519

	}
	,
		abstract = { This paper describes a novel method for edge feature detection of document images based on wavelet decomposition and reconstruction. By applying the wavelet decomposition technique, a document image becomes a wavelet representation, i.e. the image is decomposed into a set of wavelet approximation coefficients and wavelet detail coefficients. Discarding wavelet approximation, the edge extraction is implemented by means of the wavelet reconstruction technique. In consideration of the mutual frequency, overlapping will occur between wavelet approximation and wavelet details, a multiresolution-edge extraction with respect to an iterative reconstruction procedure is developed to ameliorate the quality of the reconstructed edges in this case. A novel combination of this multiresolution-edge results in clear final edges of the document images. This multi-resolution reconstruction procedure follows a coarser-to-finer searching strategy. The edge feature extraction is accompanied by an energy distribution estimation from which the levels of wavelet decomposition are adaptively controlled. Compared with the scheme of wavelet transform, our method does not incur any redundant operation. Therefore, the computational time and the memory requirement are less than those in wavelet transform. }
}




@article{SHIH2005441,
	title = "A wavelet-based multiresolution edge detection and tracking",
	journal = "Image and Vision Computing",
	volume = "23",
	number = "4",
	pages = "441 - 451",
	year = "2005",
	issn = "0262-8856",
	doi = "https://doi.org/10.1016/j.imavis.2004.11.005",
	url = "http://www.sciencedirect.com/science/article/pii/S0262885604002264",
	author = "Ming-Yu Shih and Din-Chang Tseng",
	keywords = "Edge extraction, Edge detection, Edge tracking, Wavelet transform",
	abstract = "A gradient image describes the differences of neighboring pixels in the image. Extracting edges only depending on a gradient image will results in noised and broken edges. Here, we propose a two-stage edge extraction approach with contextual-filter edge detector and multiscale edge tracker to solve the problems. The edge detector detects most edges and the tracker refines the results as well as reduces the noised or blurred influence; moreover, the extracted results are nearly thinned edges which are suitable for most applications. Based on six wavelet basis functions, qualitative and quantitative comparisons with other methods show that the proposed approach extracts better edges than the other wavelet-based edge detectors and Canny detector extract."
}

@article{pan2013low,
	title={A low-complexity screen compression scheme for interactive screen sharing},
	author={Pan, Zhaotai and Shen, Huifeng and Lu, Yan and Li, Shipeng and Yu, Nenghai},
	journal={IEEE transactions on circuits and systems for video technology},
	volume={23},
	number={6},
	pages={949--960},
	year={2013},
	publisher={IEEE}
}


@article{chen2020full,
	title={Full Reference Screen Content Image Quality Assessment by Fusing Multi-level Structure Similarity},
	author={Chen, Chenglizhao and Zhao, Hongmeng and Yang, Huan and Peng, Chong and Yu, Teng},
	journal={arXiv preprint arXiv:2008.05396},
	year={2020}
}

@article{daugman1985uncertainty,
	title={Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters},
	author={Daugman, John G},
	journal={JOSA A},
	volume={2},
	number={7},
	pages={1160--1169},
	year={1985},
	publisher={Optical Society of America}
}


@article{zhang2014vsi,
	title={VSI: A visual saliency-induced index for perceptual image quality assessment},
	author={Zhang, Lin and Shen, Ying and Li, Hongyu},
	journal={IEEE Transactions on Image processing},
	volume={23},
	number={10},
	pages={4270--4281},
	year={2014},
	publisher={IEEE}
}

@article{zhang2011practical,
	title={Practical image quality metric applied to image coding},
	author={Zhang, Fan and Ma, Lin and Li, Songnan and Ngan, King Ngi},
	journal={IEEE Transactions on Multimedia},
	volume={13},
	number={4},
	pages={615--624},
	year={2011},
	publisher={IEEE}
}


@inproceedings{ye2012unsupervised,
	title={Unsupervised feature learning framework for no-reference image quality assessment},
	author={Ye, Peng and Kumar, Jayant and Kang, Le and Doermann, David},
	booktitle={2012 IEEE conference on computer vision and pattern recognition},
	pages={1098--1105},
	year={2012},
	organization={IEEE}
}


@article{seshadrinathan2011automatic,
	title={Automatic prediction of perceptual quality of multimedia signals—a survey},
	author={Seshadrinathan, Kalpana and Bovik, Alan Conrad},
	journal={Multimedia Tools and Applications},
	volume={51},
	number={1},
	pages={163--186},
	year={2011},
	publisher={Springer}
}

@article{ma2016waterloo,
	title={Waterloo exploration database: New challenges for image quality assessment models},
	author={Ma, Kede and Duanmu, Zhengfang and Wu, Qingbo and Wang, Zhou and Yong, Hongwei and Li, Hongliang and Zhang, Lei},
	journal={IEEE Transactions on Image Processing},
	volume={26},
	number={2},
	pages={1004--1016},
	year={2016},
	publisher={IEEE}
}

@article{chandler2013seven,
	title={Seven challenges in image quality assessment: past, present, and future research},
	author={Chandler, Damon M},
	journal={ISRN Signal Processing},
	volume={2013},
	year={2013},
	publisher={Hindawi Publishing Corporation}
}

@article{lin2011perceptual,
	title={Perceptual visual quality metrics: A survey},
	author={Lin, Weisi and Kuo, C-C Jay},
	journal={Journal of visual communication and image representation},
	volume={22},
	number={4},
	pages={297--312},
	year={2011},
	publisher={Elsevier}
}

@article{wang2009mean,
	title={Mean squared error: Love it or leave it? A new look at signal fidelity measures},
	author={Wang, Zhou and Bovik, Alan C},
	journal={IEEE signal processing magazine},
	volume={26},
	number={1},
	pages={98--117},
	year={2009},
	publisher={IEEE}
}

@article{wang2002universal,
	title={A universal image quality index},
	author={Wang, Zhou and Bovik, Alan C},
	journal={IEEE signal processing letters},
	volume={9},
	number={3},
	pages={81--84},
	year={2002},
	publisher={IEEE}
}

@article{wang2004image,
	title={Image quality assessment: from error visibility to structural similarity},
	author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
	journal={IEEE transactions on image processing},
	volume={13},
	number={4},
	pages={600--612},
	year={2004},
	publisher={IEEE}
}

@article{sheikh2005live,
	title={LIVE image quality assessment database release 2},
	author={Sheikh, HR},
	journal={http://live. ece. utexas. edu/research/quality},
	year={2005}
}

@inproceedings{chen2006edge,
	title={Edge-based structural similarity for image quality assessment},
	author={Chen, Guan-Hao and Yang, Chun-Ling and Po, Lai-Man and Xie, Sheng-Li},
	booktitle={2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings},
	volume={2},
	pages={II--II},
	year={2006},
	organization={IEEE}
}

@article{sheikh2006image,
	title={Image information and visual quality},
	author={Sheikh, Hamid R and Bovik, Alan C},
	journal={IEEE Transactions on image processing},
	volume={15},
	number={2},
	pages={430--444},
	year={2006},
	publisher={IEEE}
}

@article{moorthy2011blind,
	title={Blind image quality assessment: From natural scene statistics to perceptual quality},
	author={Moorthy, Anush Krishna and Bovik, Alan Conrad},
	journal={IEEE transactions on Image Processing},
	volume={20},
	number={12},
	pages={3350--3364},
	year={2011},
	publisher={IEEE}
}


@article{kim2017deep,
	title={Deep convolutional neural models for picture-quality prediction: Challenges and solutions to data-driven image quality assessment},
	author={Kim, Jongyoo and Zeng, Hui and Ghadiyaram, Deepti and Lee, Sanghoon and Zhang, Lei and Bovik, Alan C},
	journal={IEEE Signal processing magazine},
	volume={34},
	number={6},
	pages={130--141},
	year={2017},
	publisher={IEEE}
}

@article{yang2019survey,
	title={A Survey of DNN Methods for Blind Image Quality Assessment},
	author={Yang, Xiaohan and Li, Fan and Liu, Hantao},
	journal={IEEE Access},
	volume={7},
	pages={123788--123806},
	year={2019},
	publisher={IEEE}
}
@article{okarma2019current,
	title={Current Trends and Advances in Image Quality Assessment},
	author={Okarma, Krzysztof},
	journal={Elektronika ir Elektrotechnika},
	volume={25},
	number={3},
	pages={77--84},
	year={2019}
}

@inproceedings{shen2009high,
	title={A high-performanance remote computing platform},
	author={Shen, Huifeng and Lu, Yan and Wu, Feng and Li, Shipeng},
	booktitle={2009 IEEE International Conference on Pervasive Computing and Communications},
	pages={1--6},
	year={2009},
	organization={IEEE}
}

@inproceedings{ruderman1994statistics,
	title={Statistics of natural images: Scaling in the woods},
	author={Ruderman, Daniel L and Bialek, William},
	booktitle={Advances in neural information processing systems},
	pages={551--558},
	year={1994}
}

@article{liu2014no,
	title={No-reference image quality assessment in curvelet domain},
	author={Liu, Lixiong and Dong, Hongping and Huang, Hua and Bovik, Alan C},
	journal={Signal Processing: Image Communication},
	volume={29},
	number={4},
	pages={494--505},
	year={2014},
	publisher={Elsevier}
}

@phdthesis{mittal2013natural,
	author = {{Mittal}, Anish},
	school = {The University of Texas at Austin},
	title = {{Natural scene statistics-based blind visual quality assessment in the spatial domain}},
	type = {PHD Thesis},
	year = {2013}
}

@article{yang2015perceptual,
	title={Perceptual quality assessment of screen content images},
	author={Yang, Huan and Fang, Yuming and Lin, Weisi},
	journal={IEEE Transactions on Image Processing},
	volume={24},
	number={11},
	pages={4408--4421},
	year={2015},
	publisher={IEEE}
}

@article{ni2017esim,
	title={ESIM: Edge similarity for screen content image quality assessment},
	author={Ni, Zhangkai and Ma, Lin and Zeng, Huanqiang and Chen, Jing and Cai, Canhui and Ma, Kai-Kuang},
	journal={IEEE Transactions on Image Processing},
	volume={26},
	number={10},
	pages={4818--4831},
	year={2017},
	publisher={IEEE}
}

@article{wang2016subjective,
	title={Subjective and objective quality assessment of compressed screen content images},
	author={Wang, Shiqi and Gu, Ke and Zhang, Xiang and Lin, Weisi and Zhang, Li and Ma, Siwei and Gao, Wen},
	journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
	volume={6},
	number={4},
	pages={532--543},
	year={2016},
	publisher={IEEE}
}

@article{xu2015overview,
	title={Overview of the emerging HEVC screen content coding extension},
	author={Xu, Jizheng and Joshi, Rajan and Cohen, Robert A},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	volume={26},
	number={1},
	pages={50--62},
	year={2015},
	publisher={IEEE}
}
@article{sullivan2012overview,
	title={Overview of the high efficiency video coding (HEVC) standard},
	author={Sullivan, Gary J and Ohm, Jens-Rainer and Han, Woo-Jin and Wiegand, Thomas},
	journal={IEEE Transactions on circuits and systems for video technology},
	volume={22},
	number={12},
	pages={1649--1668},
	year={2012},
	publisher={IEEE}
}

@INPROCEEDINGS{4669940, author={J. {Zhang} and R. {Kasturi}}, booktitle={2008 The Eighth IAPR International Workshop on Document Analysis Systems}, title={Extraction of Text Objects in Video Documents: Recent Progress}, year={2008}, volume={}, number={}, pages={5-17},}

@INPROCEEDINGS{5277693, author={P. {Shivakumara} and T. Q. {Phan} and C. L. {Tan}}, booktitle={2009 10th International Conference on Document Analysis and Recognition}, title={A Robust Wavelet Transform Based Technique for Video Text Detection}, year={2009}, volume={}, number={}, pages={1285-1289},} 

@inproceedings{ye2013document,
	title={Document image quality assessment: A brief survey},
	author={Ye, Peng and Doermann, David},
	booktitle={2013 12th International Conference on Document Analysis and Recognition},
	pages={723--727},
	year={2013},
	organization={IEEE}
}

@article{gaudart1993wavelet,
	title={Wavelet transform in human visual channels},
	author={Gaudart, L and Crebassa, J and Petrakian, JP},
	journal={Applied optics},
	volume={32},
	number={22},
	pages={4119--4127},
	year={1993},
	publisher={Optical Society of America}
}

@article{reisenhofer2018haar,
	title={A Haar wavelet-based perceptual similarity index for image quality assessment},
	author={Reisenhofer, Rafael and Bosse, Sebastian and Kutyniok, Gitta and Wiegand, Thomas},
	journal={Signal Processing: Image Communication},
	volume={61},
	pages={33--43},
	year={2018},
	publisher={Elsevier}
}


@book{haar1909theorie,
	title={Zur theorie der orthogonalen funktionensysteme},
	author={Haar, Alfred},
	year={1909},
	publisher={Georg-August-Universitat, Gottingen.}
}

@article{sheikh2006statistical,
	title={A statistical evaluation of recent full reference image quality assessment algorithms},
	author={Sheikh, Hamid R and Sabir, Muhammad F and Bovik, Alan C},
	journal={IEEE Transactions on image processing},
	volume={15},
	number={11},
	pages={3440--3451},
	year={2006},
	publisher={IEEE}
}

@article{jiang2019deep,
	author = {Jiang, Xuhao and Shen, Liquan and Feng, Guorui and Yu, Liangwei and An, Ping},
	file = {:media/pooryaa/New Volume/P A P E R S/Jiang2019{\_}Xuaho2.pdf:pdf},
	journal = {arXiv preprint arXiv:1903.00705},
	keywords = {FR{\_}SCI,Full Reference,Jiang2019{\_}Xuhao,QODCNN,SCI,cnn,deep learning},
	mendeley-groups = {SCI-FR},
	mendeley-tags = {FR{\_}SCI,Full Reference,Jiang2019{\_}Xuhao,QODCNN,SCI,cnn,deep learning},
	title = {{Deep Optimization model for Screen Content Image Quality Assessment using Neural Networks}},
	year = {2019}
}
@inproceedings{Lin2019,
	abstract = {In this paper, we present a lightweight visual quality assessment of screen content image (SCI) based on the local luminance edge directions and gradient magnitude. First, we use directional derivative filters (DDFs) to extract the edge direction feature which is one of the main characteristics of SCIs. To obtain the perceptual quality measures, we separately extract the edge direction and gradient magnitude for the similarity computation between the reference and distorted SCIs. Finally, considering the computational complexity, we incorporate the DDF-based feature map with the gradient magnitude map together to generate a new visual quality metric. Experimental results have demonstrated that the proposed method is able to adapt better to the human visual system than 12 representative methods based on the screen image quality assessment database (SIQAD) 1 .},
	author = {Lin, Jiaxin and Wang, Miaohui and Xie, Wuyuan},
	booktitle = {2018 IEEE 3rd International Conference on Signal and Image Processing, ICSIP 2018},
	doi = {10.1109/SIPROCESS.2018.8600420},
	file = {:media/pooryaa/New Volume/P A P E R S/lin2018{\_}Jiaxin.pdf:pdf},
	isbn = {9781538663943},
	keywords = {DSS,Directional derivatives,FR{\_}SCI,Full Reference,Human visual system,Image quality assessment (iqa),Lin2018{\_}Jiaxin,SCI,Scteen content images,fb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {DSS,FR{\_}SCI,Full Reference,Lin2018{\_}Jiaxin,SCI,fb},
	month = {jan},
	pages = {292--296},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{A Lightweight quality assessment of screen content images using directional derivative filters}},
	year = {2019}
}
@inproceedings{Layek2019,
	abstract = {Screen content images (SCI) are composed of texts, graphics, images, emails, web pages, and other computergenerated components which make it different from the pure natural images. As a result, image quality assessment (IQA) methods designed for natural images are not always suitable for screen content images. However, as time goes, many screen contents are being generated which share several properties of natural images. As a result, IQA methods for SCI need to be more generic while giving priority to the prominent SCI features. The image gradient is a very important feature for all kinds of images, especially for SCI. In this paper, we proposed a novel image gradient based similarity index (CGSI) for screen content images where the gradient is used both as a quality map and extractor for another feature map. Our previous studies show that the center part of an image is visually the most important part and HVS is more sensitive to any distortion in the middle area. To address this issue, the center area of both gradient and feature similarity maps are raised by element-wise squaring. Eventually, the final quality score is calculated using a summation of standard deviation based pooling strategy. We evaluated our proposed method on three large scale SCI databases and compared with 8 other state-of-the-art IQA methods designed for both natural and screen content images. Results show that the proposed approach provides competitive performance and defeats all other methods with a large gap in overall performance. Also, the relatively faster running time makes it suitable for most of the real-time applications.},
	author = {Layek, Md Abu and Thu, Ngo Thien and Yu, Soyeon and Chung, Taechoong and Huh, Eui Nam},
	booktitle = {International Conference on Ubiquitous and Future Networks, ICUFN},
	doi = {10.1109/ICUFN.2019.8806042},
	file = {:media/pooryaa/New Volume/P A P E R S/layek2019.pdf:pdf},
	isbn = {9781728113395},
	issn = {21658536},
	keywords = {CGSI,Center-emphasized,FR{\_}SCI,Full Reference,Image quality assessment,Layek2019{\_}Md{\_}Abu,SCI,Screen contents images,fb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {CGSI,FR{\_}SCI,Full Reference,Layek2019{\_}Md{\_}Abu,SCI,fb},
	month = {jul},
	pages = {257--262},
	publisher = {IEEE Computer Society},
	title = {{Center-Emphasized Gradient-Feature Based Quality Assessment Method for Screen Content Images}},
	volume = {2019-July},
	year = {2019}
}
@article{Wang2019,
	abstract = {Objective visual quality assessment specific for screen content images (SCIs) has been increasingly investigated over the years. In this paper, an effective full-reference quality evaluation model for SCIs is proposed, in which edge features in gradient domain (EFGD) are extracted for better visual perceptual representation. Unlike traditional edge feature extraction directly in the image pixel domain, all edge features in the proposed EFGD model are extracted based on the gradient map of input SCIs, including edge sharpness, edge brightness/contrast, and edge chrominance. Specifically, the gradient profile model that can well represent the spatial layout of edges is adopted to measure the edge sharpness degree. A novel computation way is reported to measure the edge brightness and contrast change between the reference and distorted SCIs, while color moments are used to account for the color chrominance variation. In addition, an adaptive weighting strategy is designed to adjust the effects of these three kinds of edge features, according to the statistical distributions of the input SCIs. Moreover, the maximum value of edge sharpness features is extracted from the test SCIs as the pooling weight to get the final image quality assessment (IQA) score. The experimental results on two commonly used SCIs databases have verified the superiorities of the EFGD model and show that the EFGD model is in more conformity with the subjective assessment results than most of the existing IQA models.},
	author = {Wang, Ruifeng and Yang, Huan and Pan, Zhenkuan and Huang, Baoxiang and Hou, Guojia},
	doi = {10.1109/ACCESS.2018.2889992},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2019 - Screen Content Image Quality Assessment with Edge Features in Gradient Domain.pdf:pdf},
	issn = {21693536},
	journal = {IEEE Access},
	keywords = {EFGD,FR{\_}SCI,Full Reference,Image quality assessment,SCI,Wang2019{\_}Ruifeng,edge feature,fb,gradient domain,screen content image},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {EFGD,FR{\_}SCI,Full Reference,SCI,Wang2019{\_}Ruifeng,fb},
	pages = {5285--5295},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Screen Content Image Quality Assessment with Edge Features in Gradient Domain}},
	volume = {7},
	year = {2019}
}
@article{Yang2019,
	author = {Yang, Qi and Ma, Zhan and Xu, Yiling and Yang, Le and Zhang, Wenjun and Sun, Jun},
	doi = {10.1109/TBC.2019.2954063},
	file = {:media/pooryaa/New Volume/P A P E R S/yang2019.pdf:pdf},
	issn = {0018-9316},
	journal = {IEEE Transactions on Broadcasting},
	keywords = {FR{\_}SCI,Full Reference,MSEA,SCI,Yang2019{\_}Qi,fb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Full Reference,MSEA,SCI,Yang2019{\_}Qi,fb},
	pages = {1--12},
	title = {{Modeling the Screen Content Image Quality via Multiscale Edge Attention Similarity}},
	url = {https://ieeexplore.ieee.org/document/8930019/},
	year = {2019}
}
@article{gu2017evaluating,
	author = {Gu, Ke and Qiao, Junfei and Min, Xiongkuo and Yue, Guanghui and Lin, Weisi and Thalmann, Daniel},
	file = {:media/pooryaa/New Volume/P A P E R S/gu2017 (2).pdf:pdf},
	journal = {IEEE transactions on visualization and computer graphics},
	keywords = {FR{\_}SCI,Full Reference,Gu2017,SCI,SVQI,fb},
	mendeley-groups = {SCI-FR},
	mendeley-tags = {SVQI,Full Reference,SCI,FR{\_}SCI,fb,Gu2017},
	number = {10},
	pages = {2689--2701},
	publisher = {IEEE},
	title = {{Evaluating quality of screen content images via structural variation analysis}},
	volume = {24},
	year = {2017}
}
@article{Gu2016a,
	author = {Gu, Ke and Wang, Shiqi and Yang, Huan and Lin, Weisi and Zhai, Guangtao and Yang, Xiaokang and Zhang, Wenjun},
	doi = {10.1109/TMM.2016.2547343},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu et al. - 2016 - Saliency-Guided Quality Assessment of Screen Content Images.pdf:pdf;::},
	isbn = {9781479965366},
	issn = {15209210},
	journal = {IEEE Transactions on Multimedia},
	keywords = {FR{\_}SCI,Gu2016,SCI,SQMS,Screen content images (SCIs),fb,image quality assessment (IQA),visual saliency},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Gu2016,SCI,SQMS,fb},
	number = {6},
	pages = {1098--1110},
	title = {{Saliency-Guided Quality Assessment of Screen Content Images}},
	volume = {18},
	year = {2016}
}
@article{Ni2016direction,
	abstract = {In this letter, we make the first attempt to explore the usage of the gradient direction to conduct the perceptual quality assessment of the screen content images (SCIs). Specifically, the proposed approach first extracts the gradient direction based on the local information of the image gradient magnitude, which not only preserves gradient direction consistency in local regions, but also demonstrates sensitivities to the distortions introduced to the SCI. A deviation-based pooling strategy is subsequently utilized to generate the corresponding image quality index. Moreover, we investigate and demonstrate the complementary behaviors of the gradient direction and magnitude for SCI quality assessment. By jointly considering them together, our proposed SCI quality metric outperforms the state-of-the-art quality metrics in terms of correlation with human visual system perception.},
	author = {Ni, Zhangkai and Ma, Lin and Zeng, Huanqiang and Cai, Canhui and Ma, Kai Kuang},
	doi = {10.1109/LSP.2016.2599294},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - 2016 - Gradient Direction for Screen Content Image Quality Assessment.pdf:pdf},
	isbn = {1070-9908 VO - 23},
	issn = {10709908},
	journal = {IEEE Signal Processing Letters},
	keywords = {FR{\_}SCI,Human visual system,Ni2016,SCI,SCI{\_}GSS,fb,gradient direction,image quality assessment,screen content image (SCI)},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Ni2016,SCI,SCI{\_}GSS,fb},
	number = {10},
	pages = {1394--1398},
	title = {{Gradient Direction for Screen Content Image Quality Assessment}},
	volume = {23},
	year = {2016}
}
@inproceedings{Ni2016,
	abstract = {Since the human visual system (HVS) is highly sensitive to edges, a novel image quality assessment (IQA) metric for as-sessing screen content images (SCIs) is proposed in this pa-per. The turnkey novelty lies in the use of an existing para-metric edge model to extract two types of salient attributes— namely, edge contrast and edge width, for the distorted SCI under assessment and its original SCI, respectively. The ex-tracted information is subject to conduct similarity measure-ments on each attribute, independently. The obtained similar-ity scores are then combined using our proposed edge-width pooling strategy to generate the final IQA score. Hopefully, this score is consistent with the judgment made by the HVS. Experimental results have shown that the proposed IQA met-ric produces higher consistency with that of the HVS on the evaluation of the image quality of the distorted SCI than that of other state-of-the-art IQA metrics.},
	author = {Ni, Zhangkai and Ma, Lin and Zeng, Huanqiang and Cai, Canhui and Ma, Kai-Kuang},
	booktitle = {2016 IEEE International Conference on Image Processing (ICIP)},
	doi = {10.1109/ICIP.2016.7532323},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - 2016 - Screen content image quality assessment using edge model.pdf:pdf},
	isbn = {978-1-4673-9961-6},
	keywords = {EMSQA,FR{\_}SCI,Index Terms— Image quality assessment,Ni2016,SCI,edge model,fb,screen content image},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {EMSQA,FR{\_}SCI,Ni2016,SCI,fb},
	pages = {81--85},
	title = {{Screen content image quality assessment using edge model}},
	url = {http://ieeexplore.ieee.org/document/7532323/},
	year = {2016}
}
@article{Wang2016,
	abstract = {Screen content image (SCI) has recently emerged as an active topic due to the rapidly increasing demand in many graphically rich services such as wireless displays and virtual desktops. Image quality models play an important role in measuring and optimizing user experience of SCI compression and transmission systems, but are currently lacking. SCIs are often composed of pictorial regions and computer generated textual/graphical content, which exhibit different statistical properties that often lead to different viewer behaviors. Inspired by this, we propose an objective quality assessment approach for SCIs that incorporates both visual field adaptation and information content weighting into structural similarity based local quality assessment. Furthermore, we develop a perceptual screen content coding scheme based on the newly proposed quality assessment measure, targeting at further improving the SCI compression performance. Experimental results show that the proposed quality assessment method not only better predicts the perceptual quality of SCIs, but also demonstrates great potentials in the design of perceptually optimal SCI compression schemes.},
	author = {Wang, S and Gu, K and Zeng, K and Wang, Z and Lin, W},
	doi = {10.1109/MCG.2016.46},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Objective Quality Assessment and Perceptual Compression of Screen Content Images.pdf:pdf},
	issn = {0272-1716},
	journal = {IEEE Computer Graphics and Applications},
	keywords = {Computers,Distortion,FR{\_}SCI,Image coding,Indexes,Quality assessment,SCI,SQI,Visualization,Wang2016{\_}Shiqi,sb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,SCI,SQI,Wang2016{\_}Shiqi,sb},
	number = {99},
	pages = {1},
	title = {{Objective Quality Assessment and Perceptual Compression of Screen Content Images}},
	volume = {PP},
	year = {2016}
}
@inproceedings{Fang2016,
	author = {Fang, Yuming and Yan, Jiebin and Liu, Jiaying and Wang, Shiqi and Li, Qiaohong and Guo, Zongming},
	booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	doi = {10.1007/978-3-319-48896-7_60},
	file = {:media/pooryaa/New Volume/P A P E R S/Fang2016{\_}Yuming.pdf:pdf},
	isbn = {9783319488950},
	issn = {16113349},
	keywords = {FR{\_}SCI,Fang2016{\_}Yuming,Full-reference quality assessment,SCI,Screen content image,Visual quality assessment,sb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Fang2016{\_}Yuming,SCI,sb},
	pages = {609--616},
	title = {{Objective quality assessment of screen content images by structure information}},
	volume = {9917 LNCS},
	year = {2016}
}
@article{Yang2015,
	abstract = {Research on screen content images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study on perceptual quality assessment of distorted SCIs subjectively and objectively. We construct a large-scale screen image quality assessment database (SIQAD) consisting of 20 source and 980 distorted SCIs. In order to get the subjective quality scores and investigate, which part (text or picture) contributes more to the overall visual quality, the single stimulus methodology with 11 point numerical scale is employed to obtain three kinds of subjective scores corresponding to the entire, textual, and pictorial regions, respectively. According to the analysis of subjective data, we propose a weighting strategy to account for the correlation among these three kinds of subjective scores. Furthermore, we design an objective metric to measure the visual quality of distorted SCIs by considering the visual difference of textual and pictorial regions. The experimental results demonstrate that the proposed SCI perceptual quality assessment scheme, consisting of the objective metric and the weighting strategy, can achieve better performance than 11 state-of-the-art IQA methods. To the best of our knowledge, the SIQAD is the first large-scale database published for quality evaluation of SCIs, and this research is the first attempt to explore the perceptual quality assessment of distorted SCIs},
	annote = {- a list of references of image quality assessment databases

		- " Naturalness Value of an Image Pixel "},
	author = {Yang, Huan and Fang, Yuming and Lin, Weisi},
	doi = {10.1109/TIP.2015.2465145},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Fang, Lin - 2015 - Perceptual Quality Assessment of Screen Content Images.pdf:pdf;::},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {FR{\_}SCI,SCI,SIQAD,SPQA,Screen content image,Yang2015,database,objective quality assessment,quality assessment,sb,subjective quality assessment},
	mendeley-groups = {D A T A B A S E S,S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,SCI,SIQAD,SPQA,Yang2015,database,sb},
	number = {11},
	pages = {4408--4421},
	title = {{Perceptual Quality Assessment of Screen Content Images}},
	volume = {24},
	year = {2015}
}
@article{Zhang2018,
	abstract = {The recent popularity of remote desktop software and live streaming of composited video has given rise to a growing number of applications that make use of the so-called screen content images that contain a mixture of text, graphics, and photographic imagery. Automatic quality assessment (QA) of screen-content images is necessary to enable tasks, such as quality monitoring, parameter adaptation, and other optimizations. Although QA of natural images has been heavily researched over the last several decades, the QA of screen content images is a relatively new topic. In this paper, we present a QA algorithm called convolutional neural network-based screen content image quality estimator (CNN-SQE), which operates via a fuzzy classification of screen content images into plain-text, computer-graphics/cartoons, and natural-image regions. The first two classes are considered to contain synthetic content (text/graphics), and the latter two classes are considered to contain naturalistic content (graphics/photographs), where the overlap of the classes allows the computer graphics/cartoons segments to be analyzed by both text-based and natural-image-based features. We present a CNN-based approach for the classification, an edge-structure-based quality degradation model, and a region-size-adaptive quality-fusion strategy. As we will demonstrate, the proposed CNN-SQE algorithm can achieve better/competitive performance as compared with the other state-of-the-art QA algorithms.},
	author = {Zhang, Yi and Chandler, Damon M. and Mou, Xuanqin},
	doi = {10.1109/TIP.2018.2851390},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Chandler, Mou - 2018 - Quality Assessment of Screen Content Images via Convolutional-Neural-Network-Based SyntheticNatural Segmen.pdf:pdf},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {CNN-SQE,FR{\_}SCI,SCI,Screen content image,Zhang2018{\_}Yi,convolutional neural network,full reference quality assessment,local entropy,sb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {CNN-SQE,FR{\_}SCI,SCI,Zhang2018{\_}Yi,sb},
	number = {10},
	pages = {5113--5128},
	title = {{Quality Assessment of Screen Content Images via Convolutional-Neural-Network-Based Synthetic/Natural Segmentation}},
	volume = {27},
	year = {2018}
}
@article{Fang2017a,
	author = {Fang, Yuming and Yan, Jiebin and Liu, Jiaying and Wang, Shiqi and Li, Qiaohong and Guo, Zongming},
	doi = {10.1109/TIP.2017.2669840},
	file = {:media/pooryaa/New Volume/P A P E R S/fang2017{\_}Yuming.pdf:pdf},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {FR{\_}SCI,Fang2017{\_}Yuming,SCI,SFUW,Visual quality assessment,full-reference quality assessment,sb,screen content image,uncertainty weighting},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Fang2017{\_}Yuming,SCI,SFUW,sb},
	number = {4},
	pages = {2016--2027},
	title = {{Objective Quality Assessment of Screen Content Images by Uncertainty Weighting}},
	volume = {26},
	year = {2017}
}
@inproceedings{gu2015screen,
	author = {Gu, Ke and Wang, Shiqi and Zhai, Guangtao and Ma, Siwei and Lin, Weisi},
	booktitle = {Circuits and Systems (ISCAS), 2015 IEEE International Symposium on},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu et al. - 2015 - Screen image quality assessment incorporating structural degradation measurement.pdf:pdf;::},
	keywords = {FR{\_}SCI,Gu2015,SCI,SIQM,fb},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {Gu2015,SCI,SIQM,FR{\_}SCI,fb},
	organization = {IEEE},
	pages = {125--128},
	title = {{Screen image quality assessment incorporating structural degradation measurement}},
	year = {2015}
}
@inproceedings{8266442,
	author = {Lu, Ning and Li, Guohui},
	booktitle = {2017 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)},
	file = {:media/pooryaa/New Volume/P A P E R S/lu2017 (2).pdf:pdf},
	keywords = {FR{\_}SCI,Full Reference,SCI,fb},
	mendeley-groups = {SCI-FR},
	mendeley-tags = {FR{\_}SCI,Full Reference,SCI,fb},
	pages = {39--43},
	title = {{A full reference quality assessment approach for screen content images based on high order derivative variation model}},
	year = {2017}
}
@article{Ni2018,
	abstract = {In this paper, an accurate and efficient full-reference image quality assessment (IQA) model using the extracted Gabor features, called Gabor feature-based model (GFM), is proposed for conducting objective evaluation of screen content images (SCIs). It is well-known that the Gabor filters are highly consistent with the response of the human visual system (HVS), and the HVS is highly sensitive to the edge information. Based on these facts, the imaginary part of the Gabor filter that has odd symmetry and yields edge detection is exploited to the luminance of the reference and distorted SCI for extracting their Gabor features, respectively. The local similarities of the extracted Gabor features and two chrominance components, recorded in the LMN color space, are then measured independently. Finally, the Gabor-feature pooling strategy is employed to combine these measurements and generate the final evaluation score. Experimental simulation results obtained from two large SCI databases have shown that the proposed GFM model not only yields a higher consistency with the human perception on the assessment of SCIs but also requires a lower computational complexity, compared with that of classical and state-of-the-art IQA models.11The source code for the proposed GFM will be available at http://smartviplab.org/pubilcations/GFM.html.},
	author = {Ni, Zhangkai and Zeng, Huanqiang and Ma, Lin and Hou, Junhui and Chen, Jing and Ma, Kai Kuang},
	doi = {10.1109/TIP.2018.2839890},
	file = {:media/pooryaa/New Volume/P A P E R S/Ni2018{\_}Zhangkai.pdf:pdf},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {FR{\_}SCI,GFM,Gabor feature,Image quality assessment (IQA),Ni2018{\_}Zhangkai,SCI,fb,screen content images (SCIs)},
	mendeley-groups = {SCI-FR},
	mendeley-tags = {FR{\_}SCI,GFM,Ni2018{\_}Zhangkai,SCI,fb},
	number = {9},
	pages = {4516--4528},
	title = {{A Gabor Feature-Based Quality Assessment Model for the Screen Content Images}},
	volume = {27},
	year = {2018}
}
@article{Fu2018,
	author = {Fu, Ying and Zeng, Huanqiang and Ma, Lin and Ni, Zhangkai and Zhu, Jianqing and Ma, Kai Kuang},
	doi = {10.1109/TCSVT.2018.2854176},
	file = {:media/pooryaa/New Volume/P A P E R S/Fu2018{\_}Ying.pdf:pdf},
	issn = {10518215},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	keywords = {FR{\_}SCI,Fu2018{\_}Ying,Full Reference,Human visual system (HVS),MDOGS,SCI,fb,image quality assessment (IQA),multi-scale difference of Gaussian,screen content image (SCI)},
	mendeley-groups = {SCI-FR},
	mendeley-tags = {FR{\_}SCI,Fu2018{\_}Ying,Full Reference,MDOGS,SCI,fb},
	number = {9},
	pages = {2428--2432},
	title = {{Screen Content Image Quality Assessment Using Multi-Scale Difference of Gaussian}},
	volume = {28},
	year = {2018}
}
@inproceedings{Fu2017,
	abstract = {Considering that human visual system (HVS) is greatly sensitive to edge, in this study, we design a new full-reference objective quality assessment method for screen content images (SCIs). The key novelty lies in the extracting of the edge information by computing the Euclidean distance of luminance in the SCIs. Since HVS is greatly suitable for extracting structural information, the structure information is incorporated into our proposed model. The extracted information is then used to compute the similarity maps of the reference SCI and its distorted SCI. Finally, we combine the obtained maps by using our designed pooling strategy. Experience results have shown that the designed method get higher correlation with the subjective quality score than state-of-the-art quality assessment models.},
	author = {Fu, Ying and Zeng, Huanqiang and Ni, Zhangkai and Chen, Jing and Cai, Canhui and Ma, Kai Kuang},
	booktitle = {2017 International Symposium on Intelligent Signal Processing and Communication Systems, ISPACS 2017 - Proceedings},
	doi = {10.1109/ISPACS.2017.8266443},
	file = {:media/pooryaa/New Volume/P A P E R S/fu2017{\_}Ying{\_}Euclidean{\_}Distance.pdf:pdf},
	isbn = {9781538621592},
	keywords = {EDMS,Euclidean distance,FR{\_}SCI,Fu2017{\_}Ying,Full Reference,Image quality assessment,SCI,fb,human visual system,screen content image},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Full Reference,SCI,fb,Fu2017{\_}Ying,EDMS},
	month = {jul},
	pages = {44--49},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Screen content image quality assessment using Euclidean distance}},
	volume = {2018-Janua},
	year = {2017}
}
@article{Ni2017,
	author = {Ni, Zhangkai and Ma, Lin and Zeng, Huanqiang and Chen, Jing and Cai, Canhui and Ma, Kai Kuang},
	doi = {10.1109/TIP.2017.2718185},
	file = {:home/pooryaa/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - 2017 - ESIM Edge Similarity for Screen Content Image Quality Assessment.pdf:pdf},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {ESIM,FR{\_}SCI,Image quality assessment (IQA),Ni2017,SCI,SCID,database,edge direction,edge modeling,fb,screen content images (SCIs)},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {ESIM,Ni2017,SCI,SCID,database,FR{\_}SCI,fb},
	number = {10},
	pages = {4818--4831},
	title = {{ESIM: Edge Similarity for Screen Content Image Quality Assessment}},
	volume = {26},
	year = {2017}
}
@article{Jiang2019,
	author = {Jiang, Xuhao and Shen, Liquan and Ding, Qing and Zheng, Linru and An, Ping},
	doi = {10.1016/j.jvcir.2019.102745},
	file = {:media/pooryaa/New Volume/P A P E R S/Jiang2017{\_}Qiuping.pdf:pdf;:media/pooryaa/New Volume/P A P E R S/jiang2019{\_}Xuhao.pdf:pdf},
	issn = {10473203},
	journal = {Journal of Visual Communication and Image Representation},
	keywords = {FR{\_}SCI,Full Reference,Jiang2019{\_}Xuhao,SCI,SIQA-DF-II,cnn,deep learning},
	mendeley-groups = {S C R E E N,SCI-FR},
	mendeley-tags = {FR{\_}SCI,Full Reference,Jiang2019{\_}Xuhao,SCI,cnn,deep learning,SIQA-DF-II},
	month = {dec},
	pages = {102745},
	title = {{Screen Content Image Quality Assessment based on Convolutional Neural Networks}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047320319303669},
	volume = {67},
	year = {2019}
}

@inproceedings{Yang2012,
	author = {Yang, H and Lin, W and Deng, C},
	booktitle = {IEEE International Conference on Image Processing},
	pages = {1569--1572},
	title = {{Image activity measure (IAM) for screen image segmentation}},
	year = {2012}
}

@inproceedings{minaee2015screen,
	title={Screen content image segmentation using least absolute deviation fitting},
	author={Minaee, Shervin and Wang, Yao},
	booktitle={2015 IEEE International Conference on Image Processing (ICIP)},
	pages={3295--3299},
	year={2015},
	organization={IEEE}
}

@inproceedings{wang2006spatial,
	title={Spatial pooling strategies for perceptual image quality assessment},
	author={Wang, Zhou and Shang, Xinli},
	booktitle={2006 International Conference on Image Processing},
	pages={2945--2948},
	year={2006},
	organization={IEEE}
}

@article{Ojala2002,
	abstract = {Presents a theoretically very simple, yet efficient,$\backslash$nmultiresolution approach to gray-scale and rotation invariant texture$\backslash$nclassification based on local binary patterns and nonparametric$\backslash$ndiscrimination of sample and prototype distributions. The method is$\backslash$nbased on recognizing that certain local binary patterns, termed$\backslash$n"uniform," are fundamental properties of local image texture and their$\backslash$noccurrence histogram is proven to be a very powerful texture feature. We$\backslash$nderive a generalized gray-scale and rotation invariant operator$\backslash$npresentation that allows for detecting the "uniform" patterns for any$\backslash$nquantization of the angular space and for any spatial resolution and$\backslash$npresents a method for combining multiple operators for multiresolution$\backslash$nanalysis. The proposed approach is very robust in terms of gray-scale$\backslash$nvariations since the operator is, by definition, invariant against any$\backslash$nmonotonic transformation of the gray scale. Another advantage is$\backslash$ncomputational simplicity as the operator can be realized with a few$\backslash$noperations in a small neighborhood and a lookup table. Experimental$\backslash$nresults demonstrate that good discrimination can be achieved with the$\backslash$noccurrence statistics of simple rotation invariant local binary patterns$\backslash$n},
	author = {Ojala, Timo and Pietik{\"{a}}inen, Matti and M{\"{a}}enp{\"{a}}{\"{a}}, Topi},
	doi = {10.1109/TPAMI.2002.1017623},
	isbn = {0162-8828},
	issn = {01628828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Brodatz,Contrast,Distribution,Histogram,Nonparametric,Outex,Texture analysis},
	number = {7},
	pages = {971--987},
	title = {{Multiresolution gray-scale and rotation invariant texture classification with local binary patterns}},
	volume = {24},
	year = {2002}
}

@article{larson2010most,
	title={Most apparent distortion: full-reference image quality assessment and the role of strategy},
	author={Larson, Eric Cooper and Chandler, Damon Michael},
	journal={Journal of electronic imaging},
	volume={19},
	number={1},
	pages={011006},
	year={2010},
	publisher={International Society for Optics and Photonics}
}

@book{gonzalez2002digital,
	title={Digital Image Processing (preview)},
	author={Gonzalez, Rafael C and Woods, Richard E},
	year={2002},
	publisher={Prentice Hall}
}

@article{Xue2014,
	abstract = {this paper proposed an image quality assessment metric, Gradient based. every easy! just calculate the gradient of reference image and current image. and use average pooling to get a gradient mean value. then calculate the standard deviation. There are three aspects to evaluate the performance of IQA model. prediction accuracy prediction monotonicity and prediction consistency.},
	author = {Xue, Wufeng and Zhang, Lei and Mou, Xuanqin and Bovik, Alan C.},
	doi = {10.1109/TIP.2013.2293423},
	isbn = {1057-7149},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {GMSD,Gradient magnitude similarity,Xue2014,full reference,image quality assessment,standard deviation pooling},
	mendeley-tags = {GMSD,Xue2014},
	number = {2},
	pages = {668--695},
	title = {{Gradient magnitude similarity deviation: A highly efficient perceptual image quality index}},
	volume = {23},
	year = {2014}
}

@phdthesis{VanBeek1995,
	author = {{Van Beek}, P.J.L.},
	school = {Delft University of Technology},
	title = {{Edge -Based Image Representation and Coding}},
	type = {PHD Thesis},
	year = {1995}
}

@article{Hughes1996,
	abstract = {A great deal of evidence suggests that early in processing, retinal images are filtered by parallel, spatial frequency selective channels. We attempt to incorporate this view of early vision with the principle of global precedence, which holds that Gestalt-like processes sensitive to global image configurations tend to dominate local feature processing in human pattern perception. Global precedence is inferred from the pattern of reaction times observed when visual patterns contain multiple cues at different levels of spatial scale. Specifically, it is frequently observed that global processing times are largely unaffected by conflicting local cues, but local processing times are substantially lengthened by conflicting global cues. The asymmetry of these effects suggests the dominant role of global configurations. Since global spatial information is effectively represented by low spatial frequencies, global precedence potentially implies a low frequency dominance. The thesis is that low spatial frequencies tend to be available before information carried by higher frequency bands, producing a coarse-to-fine temporal order in visual spatial perception. It is suggested that a variety of factors contribute to the ''prior entry'' of low frequency information, including the high contrast gain of the magnocellular pathway the amplitude spectra typical of natural images, and inhibitory interactions between the parallel frequency-tuned channels. Evidence suggesting a close relationship between global precedence and spatial frequency channels is provided by observations that the essential features of the global precedence effect are obtained using patterns consisting of low and high frequency sinusoids. The hypothesis that these asymmetric interference effects are due to interactions between parallel spatial channels is supported by an analysis of reaction times (RTs), which shows that RTs to redundant low and high frequency cues produce less facilitation than predictions that assume the channels are independent. In view of previous work showing that global precedence depends upon the low frequency content of the stimuli, we suggest that low spatial frequencies represent the sine qua non for the dominance of configurational cues in human pattern perception, and that this configurational dominance reflects the microgenesis of visual pattern perception. This general view of the temporal dynamics of visual pattern recognition is discussed, is considered from an evolutionary perspective, and is related to certain statistical regularities in natural scenes. Potential adaptive advantages of an interactive parallel architecture that confers an initial processing advantage to low resolution information are explored.},
	author = {Hughes, Howard C. and Nozawa, George and Kitterle, Frederick},
	doi = {10.1162/jocn.1996.8.3.197},
	file = {:media/pooryaa/New Volume/P A P E R S/hughes1996.pdf:pdf},
	issn = {0898929X},
	journal = {Journal of Cognitive Neuroscience},
	number = {3},
	pages = {197--230},
	title = {{Global precedence, spatial frequency channels, and the statistics of natural images}},
	volume = {8},
	year = {1996}
}

@article{zhou2018blind,
	title={Blind quality index for multiply distorted images using biorder structure degradation and nonlocal statistics},
	author={Zhou, Yu and Li, Leida and Wu, Jinjian and Gu, Ke and Dong, Weisheng and Shi, Guangming},
	journal={IEEE Transactions on Multimedia},
	volume={20},
	number={11},
	pages={3019--3032},
	year={2018},
	publisher={IEEE}
}

@article{gu2017fast,
	title={A fast reliable image quality predictor by fusing micro-and macro-structures},
	author={Gu, Ke and Li, Leida and Lu, Hong and Min, Xiongkuo and Lin, Weisi},
	journal={IEEE Transactions on Industrial Electronics},
	volume={64},
	number={5},
	pages={3903--3912},
	year={2017},
	publisher={IEEE}
}


@article{larsson2006orientation,
	title={Orientation-selective adaptation to first-and second-order patterns in human visual cortex},
	author={Larsson, Jonas and Landy, Michael S and Heeger, David J},
	journal={Journal of neurophysiology},
	volume={95},
	number={2},
	pages={862--881},
	year={2006},
	publisher={American Physiological Society}
}

@article{li2000automatic,
	title={Automatic text detection and tracking in digital video},
	author={Li, Huiping and Doermann, David and Kia, Omid},
	journal={IEEE transactions on image processing},
	volume={9},
	number={1},
	pages={147--156},
	year={2000},
	publisher={IEEE}
}

@article{wu1999textfinder,
	title={Textfinder: An automatic system to detect and recognize text in images},
	author={Wu, Victor and Manmatha, Raghavan and Riseman, Edward M.},
	journal={IEEE Transactions on pattern analysis and machine intelligence},
	volume={21},
	number={11},
	pages={1224--1229},
	year={1999},
	publisher={IEEE}
}

@article{xue2014blind,
	title={Blind image quality assessment using joint statistics of gradient magnitude and Laplacian features},
	author={Xue, Wufeng and Mou, Xuanqin and Zhang, Lei and Bovik, Alan C and Feng, Xiangchu},
	journal={IEEE Transactions on Image Processing},
	volume={23},
	number={11},
	pages={4850--4862},
	year={2014},
	publisher={IEEE}
}

@article{heydari2019low,
	title={A low complexity wavelet-based blind image quality evaluator},
	author={Heydari, Maryam and Cheraaqee, Pooryaa and Mansouri, Azadeh and Mahmoudi-Aznaveh, Ahmad},
	journal={Signal Processing: Image Communication},
	volume={74},
	pages={280--288},
	year={2019},
	publisher={Elsevier}
}


@article{zhang2011fsim,
	title={FSIM: A feature similarity index for image quality assessment},
	author={Zhang, Lin and Zhang, Lei and Mou, Xuanqin and Zhang, David},
	journal={IEEE transactions on Image Processing},
	volume={20},
	number={8},
	pages={2378--2386},
	year={2011},
	publisher={IEEE}
}

@inproceedings{wang2017study,
	title={Study of subjective and objective quality assessment for screen content images},
	author={Wang, Xu and Cao, Lei and Zhu, Yingying and Zhang, Yun and Jiang, Jianmin and Kwong, Sam},
	booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
	pages={750--754},
	year={2017},
	organization={IEEE}
}

@ARTICLE{8000398, author={X. {Min} and K. {Ma} and K. {Gu} and G. {Zhai} and Z. {Wang} and W. {Lin}}, journal={IEEE Transactions on Image Processing}, title={Unified Blind Quality Assessment of Compressed Natural, Graphic, and Screen Content Images}, year={2017}, volume={26}, number={11}, pages={5462-5474},}

@misc{VQEG2000,
	abstract = {FRTV Phase I is the first validation experiment conducted by VQEG. This test examined Full References (FR) and No Reference (NR) objective video quality models that predicted the quality of standard definition television (625-line and 525-line). Models were submitted in 1999 and VQEG's Final Report was approved June, 2000. All NR models were withdrawn. The FRTV Phase I subjective data are included in the final report; and all video sequences are available to researchers. Models that are trained on these datasets must not be compared to the models submitted to VQEG for independent validation in 1999. Such a comparison is misleading, because the experiments contain mainly source scenes and HRCs that were unknown to the model developers},
	author = {VQEG},
	booktitle = {http://www.its.bldrdoc.gov/vqeg/projects/frtv phaseI},
	title = {{Final report from the video quality experts group on the validation of objective quality metrics for video quality assessment}},
	year = {2000}
}

@inproceedings{ponomarenko2013color,
	title={Color image database TID2013: Peculiarities and preliminary results},
	author={Ponomarenko, Nikolay and Ieremeiev, Oleg and Lukin, Vladimir and Egiazarian, Karen and Jin, Lina and Astola, Jaakko and Vozel, Benoit and Chehdi, Kacem and Carli, Marco and Battisti, Federica and others},
	booktitle={european workshop on visual information processing (EUVIP)},
	pages={106--111},
	year={2013},
	organization={IEEE}
}

@article{ponomarenko2009tid2008,
	title={TID2008-a database for evaluation of full-reference visual quality assessment metrics},
	author={Ponomarenko, Nikolay and Lukin, Vladimir and Zelensky, Alexander and Egiazarian, Karen and Carli, Marco and Battisti, Federica},
	journal={Advances of Modern Radioelectronics},
	volume={10},
	number={4},
	pages={30--45},
	year={2009}
}

@inproceedings{jayaraman2012objective,
	title={Objective quality assessment of multiply distorted images},
	author={Jayaraman, Dinesh and Mittal, Anish and Moorthy, Anush K and Bovik, Alan C},
	booktitle={2012 Conference record of the forty sixth asilomar conference on signals, systems and computers (ASILOMAR)},
	pages={1693--1697},
	year={2012},
	organization={IEEE}
}

@article{sun2017mdid,
	title={MDID: A multiply distorted image database for image quality assessment},
	author={Sun, Wen and Zhou, Fei and Liao, Qingmin},
	journal={Pattern Recognition},
	volume={61},
	pages={153--168},
	year={2017},
	publisher={Elsevier}
}

@article{gu2014hybrid,
	title={Hybrid no-reference quality metric for singly and multiply distorted images},
	author={Gu, Ke and Zhai, Guangtao and Yang, Xiaokang and Zhang, Wenjun},
	journal={IEEE Transactions on Broadcasting},
	volume={60},
	number={3},
	pages={555--567},
	year={2014},
	publisher={IEEE}
}

@inproceedings{kadid10k,
	title={KADID-10k: A Large-scale Artificially 
		Distorted IQA Database},
	author={Lin, Hanhe and Hosu, Vlad and Saupe, Dietmar},
	booktitle={2019 Tenth International Conference on 
		Quality of Multimedia Experience (QoMEX)},
	pages={1--3},
	year={2019},
	organization={IEEE}}

	@article{mansouri2019ssvd,
		title={SSVD: structural SVD-based image quality assessment},
		author={Mansouri, Azadeh and Mahmoudi-Aznaveh, Ahmad},
		journal={Signal Processing: Image Communication},
		volume={74},
		pages={54--63},
		year={2019},
		publisher={Elsevier}
	}

@article{zhou2019visual,
	title={Visual quality assessment for super-resolved images: database and method},
	author={Zhou, Fei and Yao, Rongguo and Liu, Bozhi and Qiu, Guoping},
	journal={IEEE Transactions on Image Processing},
	volume={28},
	number={7},
	pages={3528--3541},
	year={2019},
	publisher={IEEE}
}

@article{zhu2018hypothesis,
	title={On hypothesis testing for comparing image quality assessment metrics [tips \& tricks]},
	author={Zhu, Rui and Zhou, Fei and Yang, Wenming and Xue, Jing-Hao},
	journal={IEEE Signal Processing Magazine},
	volume={35},
	number={4},
	pages={133--136},
	year={2018},
	publisher={IEEE}
}

@inproceedings{wang2019blind,
	title={Blind Quality Assessment of Multiply Distorted Images Using Deep Neural Networks},
	author={Wang, Zhongling and Athar, Shahrukh and Wang, Zhou},
	booktitle={International Conference on Image Analysis and Recognition},
	pages={89--101},
	year={2019},
	organization={Springer}
}

@article{trees1977forest,
	title={Forest before trees: The precedence of global features in visual perception},
	author={Navon, David},
	journal={Cognitive psychology},
	volume={353},
	pages={383},
	year={1977}
}

@article{lennie1980parallel,
	title={Parallel visual pathways: a review},
	author={Lennie, Peter},
	journal={Vision research},
	volume={20},
	number={7},
	pages={561--594},
	year={1980},
	publisher={Elsevier}
}

@inproceedings{ninassi2008performance,
	title={On the performance of human visual system based image quality assessment metric using wavelet domain},
	author={Ninassi, Alexandre and Le Meur, Olivier and Le Callet, Patrick and Barba, Dominique},
	booktitle={SPIE Conference Human Vision and Electronic Imaging XIII},
	pages={680610.1-680610.12},
	year={2008}
}

@article{shokrollahi2020histogram,
	title={Histogram modification based enhancement along with contrast-changed image quality assessment},
	author={Shokrollahi, Ayub and Maybodi, Babak Mazloom-Nezhad and Mahmoudi-Aznaveh, Ahmad},
	journal={Multimedia Tools and Applications},
	pages={1--22},
	year={2020},
	publisher={Springer}
}
